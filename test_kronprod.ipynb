{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some fake data\n",
    "ntrials_small = 200\n",
    "ntrials_large = 1000\n",
    "ntimes = 3\n",
    "ninputs = 6\n",
    "\n",
    "y_small = np.random.normal(size=(ntrials_small,ntimes))\n",
    "x_small = np.random.normal(size=(ntrials_small,ninputs))\n",
    "y_small_flat = np.ndarray.flatten(y_small) \n",
    "\n",
    "y_large = np.random.normal(size=(ntrials_large,ntimes))\n",
    "x_large = np.random.normal(size=(ntrials_large,ninputs))\n",
    "y_large_flat = np.ndarray.flatten(y_large) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pymc models\n",
    "\n",
    "# MatrixNormal, Small data\n",
    "with pm.Model() as mn_small:\n",
    "    \n",
    "    # Priors\n",
    "    muvec = pm.Normal('muvec', shape=ntimes)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10., testval=0.5)\n",
    "    packed_L = pm.LKJCholeskyCov('packed_L', n=ntimes, eta=2., sd_dist=pm.HalfCauchy.dist(2.5))\n",
    "    ell = pm.HalfCauchy('ell', beta=10., testval=0.5, shape=ninputs)\n",
    "\n",
    "    # Covariance function/matrices\n",
    "    cor = pm.gp.cov.ExpQuad(input_dim=ninputs, ls=ell)\n",
    "    K = cor(x_small)\n",
    "    L = pm.expand_packed_triangular(ntimes, packed_L)\n",
    "\n",
    "    # Mean matrix\n",
    "    M = pm.Deterministic('M', tt.tile(muvec,(y_small.shape[0],1)))\n",
    "\n",
    "    # Likelihood\n",
    "    y = pm.MatrixNormal('y', mu=M, rowcov=K, colchol=L, observed=y_small, shape=y_small.shape)\n",
    "\n",
    "\n",
    "# KroneckerNormal, Small data\n",
    "with pm.Model() as kn_small:\n",
    "    \n",
    "    # Priors\n",
    "    muvec = pm.Normal('muvec', shape=ntimes)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10., testval=0.5)\n",
    "    packed_L = pm.LKJCholeskyCov('packed_L', n=ntimes, eta=2., sd_dist=pm.HalfCauchy.dist(2.5))\n",
    "    ell = pm.HalfCauchy('ell', beta=10., testval=0.5, shape=ninputs)\n",
    "\n",
    "    # Covariance function/matrices\n",
    "    cor = pm.gp.cov.ExpQuad(input_dim=ninputs, ls=ell)\n",
    "    K = cor(x_small)\n",
    "    L = pm.expand_packed_triangular(ntimes, packed_L)\n",
    "    S = L.dot(L.T)\n",
    "    evds = [tt.nlinalg.eigh(Ki) for Ki in [K, S]]\n",
    "\n",
    "    # Mean function\n",
    "    M = pm.Deterministic('M', tt.repeat(muvec,y_small.shape[0]))\n",
    "\n",
    "    # Likelihood\n",
    "    y = pm.KroneckerNormal('y', mu=M, evds=evds, observed=y_small_flat, sigma=sigma)\n",
    "  \n",
    "    \n",
    "# MatrixNormal, Large data\n",
    "with pm.Model() as mn_large:\n",
    "    \n",
    "    # Priors\n",
    "    muvec = pm.Normal('muvec', shape=ntimes)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10., testval=0.5)\n",
    "    packed_L = pm.LKJCholeskyCov('packed_L', n=ntimes, eta=2., sd_dist=pm.HalfCauchy.dist(2.5))\n",
    "    ell = pm.HalfCauchy('ell', beta=10., testval=0.5, shape=ninputs)\n",
    "\n",
    "    # Covariance function/matrices\n",
    "    cor = pm.gp.cov.ExpQuad(input_dim=ninputs, ls=ell)\n",
    "    K = cor(x_large)\n",
    "    L = pm.expand_packed_triangular(ntimes, packed_L)\n",
    "\n",
    "    # Mean matrix\n",
    "    M = pm.Deterministic('M', tt.tile(muvec,(y_large.shape[0],1)))\n",
    "\n",
    "    # Likelihood\n",
    "    y = pm.MatrixNormal('y', mu=M, rowcov=K, colchol=L, observed=y_large, shape=y_large.shape)\n",
    "    \n",
    "\n",
    "# KroneckerNormal, Large data\n",
    "with pm.Model() as kn_large:\n",
    "    \n",
    "    # Priors\n",
    "    muvec = pm.Normal('muvec', shape=ntimes)\n",
    "    sigma = pm.HalfCauchy('sigma', beta=10., testval=0.5)\n",
    "    packed_L = pm.LKJCholeskyCov('packed_L', n=ntimes, eta=2., sd_dist=pm.HalfCauchy.dist(2.5))\n",
    "    ell = pm.HalfCauchy('ell', beta=10., testval=0.5, shape=ninputs)\n",
    "\n",
    "    # Covariance function/matrices\n",
    "    cor = pm.gp.cov.ExpQuad(input_dim=ninputs, ls=ell)\n",
    "    K = cor(x_large)\n",
    "    L = pm.expand_packed_triangular(ntimes, packed_L)\n",
    "    S = L.dot(L.T)\n",
    "    evds = [tt.nlinalg.eigh(Ki) for Ki in [K, S]]\n",
    "\n",
    "    # Mean function\n",
    "    M = pm.Deterministic('M', tt.repeat(muvec,y_large.shape[0]))\n",
    "\n",
    "    # Likelihood\n",
    "    y = pm.KroneckerNormal('y', mu=M, evds=evds, observed=y_large_flat, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function profiling\n==================\n  Message: /Users/neklein/Python/Environments/rdxgp/lib/python3.6/site-packages/pymc3/model.py:903\n  Time in 1000 calls to Function.__call__: 1.465944e+00s\n  Time in Function.fn.__call__: 1.413333e+00s (96.411%)\n  Time in thunks: 1.366755e+00s (93.234%)\n  Total compile time: 4.073930e-01s\n    Number of Apply nodes: 70\n    Theano Optimizer time: 2.757020e-01s\n       Theano validate time: 8.796930e-03s\n    Theano Linker time (includes C, CUDA code generation/compiling): 6.367517e-02s\n       Import time 0.000000e+00s\n       Node make_thunk time 6.091809e-02s\n           Node Elemwise{Sub}[(0, 1)](TensorConstant{[[ 5.42204..0886e-01]]}, M) time 2.803087e-02s\n           Node Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0, Dot22.0) time 1.236916e-03s\n           Node InplaceDimShuffle{x,0}(Sum{axis=[1], acc_dtype=float64}.0) time 9.217262e-04s\n           Node InplaceDimShuffle{x,0}(ell) time 9.090900e-04s\n           Node InplaceDimShuffle{1,0}(Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}.0) time 8.509159e-04s\n\nTime in all call to theano.grad() 0.000000e+00s\nTime since theano import 1858.552s\nClass\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>\n  35.0%    35.0%       0.478s       4.78e-04s     Py    1000       1   pymc3.distributions.dist_math.Cholesky\n  29.4%    64.3%       0.401s       1.67e-05s     C    24000      24   theano.tensor.elemwise.Elemwise\n  16.8%    81.2%       0.230s       7.67e-05s     Py    3000       3   theano.tensor.slinalg.Solve\n  12.1%    93.3%       0.166s       1.66e-04s     Py    1000       1   theano.tensor.blas.Dot22Scalar\n   1.2%    94.5%       0.017s       1.67e-05s     Py    1000       1   theano.tensor.subtensor.AdvancedIncSubtensor\n   0.9%    95.4%       0.012s       4.08e-06s     Py    3000       3   theano.tensor.basic.ExtractDiag\n   0.8%    96.2%       0.011s       1.10e-05s     Py    1000       1   theano.tensor.blas.Dot22\n   0.8%    97.0%       0.010s       5.14e-06s     C     2000       2   theano.tensor.subtensor.IncSubtensor\n   0.6%    97.5%       0.008s       1.08e-06s     C     7000       7   theano.tensor.elemwise.DimShuffle\n   0.5%    98.0%       0.007s       2.19e-06s     C     3000       3   theano.tensor.basic.Alloc\n   0.5%    98.5%       0.006s       6.16e-06s     C     1000       1   theano.tensor.subtensor.AdvancedIncSubtensor1\n   0.4%    98.9%       0.006s       6.02e-06s     C     1000       1   theano.tensor.extra_ops.CumOp\n   0.4%    99.3%       0.005s       4.71e-07s     C    11000      11   theano.tensor.elemwise.Sum\n   0.3%    99.5%       0.003s       1.15e-06s     C     3000       3   theano.tensor.subtensor.AdvancedSubtensor1\n   0.1%    99.7%       0.002s       9.17e-07s     C     2000       2   theano.tensor.opt.MakeVector\n   0.1%    99.8%       0.001s       7.14e-07s     C     2000       2   theano.compile.ops.Shape_i\n   0.1%    99.9%       0.001s       1.06e-06s     C     1000       1   theano.tensor.basic.Reshape\n   0.1%    99.9%       0.001s       1.03e-06s     C     1000       1   theano.tensor.subtensor.Subtensor\n   0.0%   100.0%       0.001s       6.36e-07s     C     1000       1   theano.tensor.elemwise.All\n   0.0%   100.0%       0.000s       3.77e-07s     C     1000       1   theano.tensor.opt.Assert\n   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)\n\nOps\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>\n  35.0%    35.0%       0.478s       4.78e-04s     Py    1000        1   Cholesky{lower=True, destructive=False, nofail=False}\n  27.7%    62.6%       0.378s       3.78e-04s     C     1000        1   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)]\n  13.8%    76.5%       0.189s       9.46e-05s     Py    2000        2   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}\n  12.1%    88.6%       0.166s       1.66e-04s     Py    1000        1   Dot22Scalar\n   3.0%    91.6%       0.041s       4.09e-05s     Py    1000        1   Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}\n   1.2%    92.8%       0.017s       1.67e-05s     Py    1000        1   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}\n   0.9%    93.7%       0.012s       4.08e-06s     Py    3000        3   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}\n   0.8%    94.5%       0.011s       1.10e-05s     Py    1000        1   Dot22\n   0.5%    95.0%       0.007s       2.19e-06s     C     3000        3   Alloc\n   0.5%    95.5%       0.006s       6.42e-06s     C     1000        1   IncSubtensor{InplaceInc;int64}\n   0.5%    95.9%       0.006s       6.16e-06s     C     1000        1   AdvancedIncSubtensor1{no_inplace,set}\n   0.4%    96.4%       0.006s       6.02e-06s     C     1000        1   CumOp{None, add}\n   0.3%    96.7%       0.004s       3.87e-06s     C     1000        1   IncSubtensor{InplaceInc;int64::}\n   0.3%    96.9%       0.004s       3.86e-06s     C     1000        1   Elemwise{true_div,no_inplace}\n   0.3%    97.2%       0.003s       1.15e-06s     C     3000        3   AdvancedSubtensor1\n   0.2%    97.4%       0.003s       3.00e-07s     C     10000       10   Sum{acc_dtype=float64}\n   0.2%    97.6%       0.003s       9.59e-07s     C     3000        3   InplaceDimShuffle{1,0}\n   0.2%    97.8%       0.003s       1.28e-06s     C     2000        2   Elemwise{Log}[(0, 0)]\n   0.2%    98.0%       0.002s       2.19e-06s     C     1000        1   Sum{axis=[1], acc_dtype=float64}\n   0.1%    98.1%       0.002s       9.15e-07s     C     2000        2   InplaceDimShuffle{x,0}\n   ... (remaining 28 Ops account for   1.89%(0.03s) of the runtime)\n\nApply\n------\n<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>\n  35.0%    35.0%       0.478s       4.78e-04s   1000    46   Cholesky{lower=True, destructive=False, nofail=False}(Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)].0)\n  27.7%    62.6%       0.378s       3.78e-04s   1000    44   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)](TensorConstant{(1, 1) of -0.5}, Dot22Scalar.0, InplaceDimShuffle{0,x}.0, InplaceDimShuffle{x,0}.0, TensorConstant{(1, 1) of 0.0}, TensorConstant{(1, 1) of inf})\n  12.1%    74.8%       0.166s       1.66e-04s   1000    27   Dot22Scalar(Elemwise{true_div,no_inplace}.0, InplaceDimShuffle{1,0}.0, TensorConstant{-2.0})\n  10.2%    85.0%       0.140s       1.40e-04s   1000    49   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}(Cholesky{lower=True, destructive=False, nofail=False}.0, Elemwise{Sub}[(0, 1)].0)\n   3.6%    88.6%       0.050s       4.96e-05s   1000    57   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0, Dot22.0)\n   3.0%    91.6%       0.041s       4.09e-05s   1000    61   Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}(InplaceDimShuffle{1,0}.0, Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}.0)\n   1.2%    92.8%       0.017s       1.67e-05s   1000    25   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}(Alloc.0, packed_L, TensorConstant{[0 1 1 2 2 2]}, TensorConstant{[0 0 1 0 1 2]})\n   0.8%    93.6%       0.011s       1.10e-05s   1000    55   Dot22(InplaceDimShuffle{1,0}.0, Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}.0)\n   0.5%    94.1%       0.006s       6.42e-06s   1000    37   IncSubtensor{InplaceInc;int64}(Alloc.0, Elemwise{sqr,no_inplace}.0, Constant{0})\n   0.5%    94.6%       0.006s       6.16e-06s   1000    20   AdvancedIncSubtensor1{no_inplace,set}(packed_L_cholesky_cov_packed__, Elemwise{Exp}[(0, 0)].0, TensorConstant{[0 2 5]})\n   0.4%    95.0%       0.006s       6.02e-06s   1000    38   CumOp{None, add}(Elemwise{Sqr}[(0, 0)].0)\n   0.4%    95.4%       0.006s       5.98e-06s   1000    64   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}.0)\n   0.3%    95.7%       0.004s       4.02e-06s   1000    12   Alloc(muvec, TensorConstant{200}, TensorConstant{1}, TensorConstant{1}, Shape_i{0}.0)\n   0.3%    96.0%       0.004s       3.87e-06s   1000    47   IncSubtensor{InplaceInc;int64::}(IncSubtensor{InplaceInc;int64}.0, Elemwise{Sub}[(0, 0)].0, Constant{1})\n   0.3%    96.3%       0.004s       3.86e-06s   1000    15   Elemwise{true_div,no_inplace}(TensorConstant{[[-3.22253..7221e+00]]}, InplaceDimShuffle{x,0}.0)\n   0.2%    96.5%       0.003s       3.21e-06s   1000    48   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Cholesky{lower=True, destructive=False, nofail=False}.0)\n   0.2%    96.8%       0.003s       3.04e-06s   1000    30   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0)\n   0.2%    96.9%       0.002s       2.19e-06s   1000    35   Sum{axis=[1], acc_dtype=float64}(Elemwise{Sqr}[(0, 0)].0)\n   0.1%    97.1%       0.002s       2.00e-06s   1000     1   AdvancedSubtensor1(packed_L_cholesky_cov_packed__, TensorConstant{[0 2 5]})\n   0.1%    97.2%       0.002s       1.64e-06s   1000    51   Elemwise{Log}[(0, 0)](ExtractDiag{offset=0, axis1=0, axis2=1, view=False}.0)\n   ... (remaining 50 Apply instances account for 2.82%(0.04s) of the runtime)\n\nHere are tips to potentially make your code run faster\n                 (if you think of new ones, suggest them on the mailing list).\n                 Test them first, as they are not guaranteed to always provide a speedup.\n  - Try the Theano flag floatX=float32\n  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.\n"
     ]
    }
   ],
   "source": [
    "# Profile small models\n",
    "mn_small.profile(mn_small.logpt).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function profiling\n==================\n  Message: /Users/neklein/Python/Environments/rdxgp/lib/python3.6/site-packages/pymc3/model.py:903\n  Time in 1000 calls to Function.__call__: 9.589539e+00s\n  Time in Function.fn.__call__: 9.534008e+00s (99.421%)\n  Time in thunks: 9.478535e+00s (98.842%)\n  Total compile time: 6.197667e-01s\n    Number of Apply nodes: 77\n    Theano Optimizer time: 3.953729e-01s\n       Theano validate time: 1.238537e-02s\n    Theano Linker time (includes C, CUDA code generation/compiling): 1.625328e-01s\n       Import time 0.000000e+00s\n       Node make_thunk time 1.592040e-01s\n           Node for{cpu,scan_fn}(TensorConstant{1}, Elemwise{Sub}[(0, 1)].0, TensorConstant{1}, ell, packed_L, Alloc.0) time 9.073091e-02s\n           Node Elemwise{Sub}[(0, 1)](TensorConstant{[[ 5.42204..0886e-01]]}, InplaceDimShuffle{x,0}.0) time 2.813411e-02s\n           Node MakeVector{dtype='float64'}(__logp_muvec, __logp_sigma_log__, __logp_packed_L_cholesky_cov_packed__, __logp_ell_log__, __logp_y) time 1.675129e-03s\n           Node Elemwise{Sqr}[(0, 0)](InplaceDimShuffle{x}.0) time 1.526117e-03s\n           Node InplaceDimShuffle{1,0}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0) time 1.030922e-03s\n\nTime in all call to theano.grad() 0.000000e+00s\nTime since theano import 1893.735s\nClass\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>\n  50.0%    50.0%       4.743s       4.74e-03s     Py    1000       1   theano.scan_module.scan_op.Scan\n  43.2%    93.3%       4.098s       2.05e-03s     Py    2000       2   theano.tensor.nlinalg.Eigh\n   4.3%    97.6%       0.412s       1.42e-05s     C    29000      29   theano.tensor.elemwise.Elemwise\n   1.3%    98.9%       0.123s       1.23e-04s     Py    1000       1   theano.tensor.blas.Dot22Scalar\n   0.2%    99.1%       0.017s       1.73e-05s     Py    1000       1   theano.tensor.subtensor.AdvancedIncSubtensor\n   0.1%    99.2%       0.013s       1.30e-06s     C    10000      10   theano.tensor.elemwise.DimShuffle\n   0.1%    99.4%       0.013s       6.27e-06s     C     2000       2   theano.tensor.subtensor.IncSubtensor\n   0.1%    99.5%       0.012s       1.21e-05s     Py    1000       1   theano.tensor.blas.Dot22\n   0.1%    99.6%       0.008s       8.23e-06s     C     1000       1   theano.tensor.extra_ops.CumOp\n   0.1%    99.7%       0.008s       1.92e-06s     C     4000       4   theano.tensor.basic.Alloc\n   0.1%    99.7%       0.007s       7.17e-06s     C     1000       1   theano.tensor.subtensor.AdvancedIncSubtensor1\n   0.1%    99.8%       0.006s       6.42e-07s     C     9000       9   theano.tensor.elemwise.Sum\n   0.0%    99.9%       0.005s       1.57e-06s     C     3000       3   theano.tensor.subtensor.AdvancedSubtensor1\n   0.0%    99.9%       0.004s       3.54e-06s     C     1000       1   theano.tensor.blas.BatchedDot\n   0.0%    99.9%       0.003s       2.75e-06s     C     1000       1   theano.tensor.blas_c.CGer\n   0.0%    99.9%       0.002s       1.01e-06s     C     2000       2   theano.tensor.subtensor.Subtensor\n   0.0%   100.0%       0.002s       9.05e-07s     C     2000       2   theano.tensor.opt.MakeVector\n   0.0%   100.0%       0.002s       8.92e-07s     C     2000       2   theano.tensor.basic.Reshape\n   0.0%   100.0%       0.001s       4.19e-07s     C     2000       2   theano.compile.ops.Shape_i\n   0.0%   100.0%       0.001s       6.48e-07s     C     1000       1   theano.tensor.elemwise.All\n   ... (remaining 1 Classes account for   0.00%(0.00s) of the runtime)\n\nOps\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>\n  50.0%    50.0%       4.743s       4.74e-03s     Py    1000        1   for{cpu,scan_fn}\n  43.2%    93.3%       4.098s       2.05e-03s     Py    2000        2   Eigh{UPLO='L'}\n   4.0%    97.3%       0.377s       3.77e-04s     C     1000        1   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)]\n   1.3%    98.6%       0.123s       1.23e-04s     Py    1000        1   Dot22Scalar\n   0.2%    98.7%       0.017s       1.73e-05s     Py    1000        1   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}\n   0.1%    98.9%       0.012s       1.21e-05s     Py    1000        1   Dot22\n   0.1%    99.0%       0.008s       8.23e-06s     C     1000        1   CumOp{None, add}\n   0.1%    99.0%       0.008s       1.92e-06s     C     4000        4   Alloc\n   0.1%    99.1%       0.007s       7.17e-06s     C     1000        1   AdvancedIncSubtensor1{no_inplace,set}\n   0.1%    99.2%       0.007s       6.87e-06s     C     1000        1   IncSubtensor{InplaceInc;int64}\n   0.1%    99.2%       0.006s       5.67e-06s     C     1000        1   IncSubtensor{InplaceInc;int64::}\n   0.0%    99.3%       0.005s       1.57e-06s     C     3000        3   AdvancedSubtensor1\n   0.0%    99.3%       0.004s       1.09e-06s     C     4000        4   InplaceDimShuffle{x,0}\n   0.0%    99.4%       0.004s       1.95e-06s     C     2000        2   InplaceDimShuffle{1,0}\n   0.0%    99.4%       0.004s       3.85e-06s     C     1000        1   Elemwise{true_div,no_inplace}\n   0.0%    99.5%       0.004s       3.80e-06s     C     1000        1   Elemwise{Log}[(0, 0)]\n   0.0%    99.5%       0.004s       4.71e-07s     C     8000        8   Sum{acc_dtype=float64}\n   0.0%    99.5%       0.004s       3.54e-06s     C     1000        1   BatchedDot\n   0.0%    99.6%       0.003s       2.75e-06s     C     1000        1   CGer{destructive}\n   0.0%    99.6%       0.003s       1.27e-06s     C     2000        2   InplaceDimShuffle{x}\n   ... (remaining 31 Ops account for   0.41%(0.04s) of the runtime)\n\nApply\n------\n<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>\n  50.0%    50.0%       4.743s       4.74e-03s   1000    44   for{cpu,scan_fn}(TensorConstant{1}, Elemwise{Sub}[(0, 1)].0, TensorConstant{1}, ell, packed_L, Alloc.0)\n  42.9%    92.9%       4.066s       4.07e-03s   1000    50   Eigh{UPLO='L'}(Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)].0)\n   4.0%    96.9%       0.377s       3.77e-04s   1000    47   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)](TensorConstant{(1, 1) of -0.5}, Dot22Scalar.0, InplaceDimShuffle{0,x}.0, InplaceDimShuffle{x,0}.0, TensorConstant{(1, 1) of 0.0}, TensorConstant{(1, 1) of inf})\n   1.3%    98.2%       0.123s       1.23e-04s   1000    31   Dot22Scalar(Elemwise{true_div,no_inplace}.0, InplaceDimShuffle{1,0}.0, TensorConstant{-2.0})\n   0.3%    98.6%       0.032s       3.22e-05s   1000    41   Eigh{UPLO='L'}(Dot22.0)\n   0.2%    98.7%       0.017s       1.73e-05s   1000    27   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}(Alloc.0, packed_L, TensorConstant{[0 1 1 2 2 2]}, TensorConstant{[0 0 1 0 1 2]})\n   0.1%    98.9%       0.012s       1.21e-05s   1000    37   Dot22(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0, InplaceDimShuffle{1,0}.0)\n   0.1%    99.0%       0.008s       8.23e-06s   1000    49   CumOp{None, add}(Elemwise{Sqr}[(0, 0)].0)\n   0.1%    99.0%       0.007s       7.17e-06s   1000    23   AdvancedIncSubtensor1{no_inplace,set}(packed_L_cholesky_cov_packed__, Elemwise{Exp}[(0, 0)].0, TensorConstant{[0 2 5]})\n   0.1%    99.1%       0.007s       6.87e-06s   1000    38   IncSubtensor{InplaceInc;int64}(Alloc.0, Elemwise{sqr,no_inplace}.0, Constant{0})\n   0.1%    99.2%       0.006s       5.67e-06s   1000    56   IncSubtensor{InplaceInc;int64::}(IncSubtensor{InplaceInc;int64}.0, Elemwise{Sub}[(0, 0)].0, Constant{1})\n   0.0%    99.2%       0.004s       3.85e-06s   1000    20   Elemwise{true_div,no_inplace}(TensorConstant{[[-3.22253..7221e+00]]}, InplaceDimShuffle{x,0}.0)\n   0.0%    99.2%       0.004s       3.80e-06s   1000    62   Elemwise{Log}[(0, 0)](Elemwise{Add}[(0, 0)].0)\n   0.0%    99.3%       0.004s       3.54e-06s   1000    69   BatchedDot(Elemwise{TrueDiv}[(0, 0)].0, Elemwise{TrueDiv}[(0, 0)].0)\n   0.0%    99.3%       0.003s       2.80e-06s   1000     5   Alloc(TensorConstant{0.0}, TensorConstant{200}, TensorConstant{3})\n   0.0%    99.3%       0.003s       2.75e-06s   1000    53   CGer{destructive}(Alloc.0, TensorConstant{1.0}, Eigh{UPLO='L'}.0, Eigh{UPLO='L'}.0)\n   0.0%    99.4%       0.002s       2.42e-06s   1000    32   InplaceDimShuffle{1,0}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0)\n   0.0%    99.4%       0.002s       2.23e-06s   1000    61   Elemwise{sqrt,no_inplace}(InplaceDimShuffle{x,0}.0)\n   0.0%    99.4%       0.002s       2.03e-06s   1000    64   Elemwise{TrueDiv}[(0, 0)](for{cpu,scan_fn}.0, Elemwise{sqrt,no_inplace}.0)\n   0.0%    99.4%       0.002s       2.03e-06s   1000     0   AdvancedSubtensor1(packed_L_cholesky_cov_packed__, TensorConstant{[0 2 5]})\n   ... (remaining 57 Apply instances account for 0.57%(0.05s) of the runtime)\n\n\nScan overhead:\n<Scan op time(s)> <sub scan fct time(s)> <sub scan op time(s)> <sub scan fct time(% scan op time)> <sub scan op time(% scan op time)> <node>\n  One scan node do not have its inner profile enabled. If you enable Theano profiler with 'theano.function(..., profile=True)', you must manually enable the profiling for each scan too: 'theano.scan_module.scan(...,profile=True)'. Or use Theano flag 'profile=True'.\n  No scan have its inner profile enabled.\nHere are tips to potentially make your code run faster\n                 (if you think of new ones, suggest them on the mailing list).\n                 Test them first, as they are not guaranteed to always provide a speedup.\n  - Try the Theano flag floatX=float32\n  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.\n"
     ]
    }
   ],
   "source": [
    "# Profile small models\n",
    "kn_small.profile(kn_small.logpt).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function profiling\n==================\n  Message: /Users/neklein/Python/Environments/rdxgp/lib/python3.6/site-packages/pymc3/model.py:903\n  Time in 1000 calls to Function.__call__: 2.593426e+01s\n  Time in Function.fn.__call__: 2.587368e+01s (99.766%)\n  Time in thunks: 2.475416e+01s (95.450%)\n  Total compile time: 4.145560e-01s\n    Number of Apply nodes: 70\n    Theano Optimizer time: 2.766502e-01s\n       Theano validate time: 9.714842e-03s\n    Theano Linker time (includes C, CUDA code generation/compiling): 7.350516e-02s\n       Import time 0.000000e+00s\n       Node make_thunk time 7.057309e-02s\n           Node Elemwise{Sub}[(0, 1)](TensorConstant{[[-0.29761..21279899]]}, M) time 2.876592e-02s\n           Node InplaceDimShuffle{x,0}(ell) time 1.753092e-03s\n           Node InplaceDimShuffle{x}(Shape_i{0}.0) time 1.728058e-03s\n           Node Cholesky{lower=True, destructive=False, nofail=False}(Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)].0) time 1.715899e-03s\n           Node Elemwise{Exp}[(0, 0)](AdvancedSubtensor1.0) time 1.145124e-03s\n\nTime in all call to theano.grad() 0.000000e+00s\nTime since theano import 1940.235s\nClass\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>\n  42.3%    42.3%      10.467s       1.05e-02s     Py    1000       1   pymc3.distributions.dist_math.Cholesky\n  37.0%    79.3%       9.170s       3.82e-04s     C    24000      24   theano.tensor.elemwise.Elemwise\n  14.1%    93.5%       3.499s       3.50e-03s     Py    1000       1   theano.tensor.blas.Dot22Scalar\n   6.0%    99.4%       1.476s       4.92e-04s     Py    3000       3   theano.tensor.slinalg.Solve\n   0.1%    99.5%       0.023s       2.31e-05s     Py    1000       1   theano.tensor.blas.Dot22\n   0.1%    99.6%       0.022s       7.23e-06s     Py    3000       3   theano.tensor.basic.ExtractDiag\n   0.1%    99.7%       0.019s       1.89e-05s     Py    1000       1   theano.tensor.subtensor.AdvancedIncSubtensor\n   0.1%    99.7%       0.014s       4.70e-06s     C     3000       3   theano.tensor.basic.Alloc\n   0.0%    99.8%       0.012s       1.10e-06s     C    11000      11   theano.tensor.elemwise.Sum\n   0.0%    99.8%       0.012s       6.04e-06s     C     2000       2   theano.tensor.subtensor.IncSubtensor\n   0.0%    99.9%       0.011s       1.64e-06s     C     7000       7   theano.tensor.elemwise.DimShuffle\n   0.0%    99.9%       0.008s       7.60e-06s     C     1000       1   theano.tensor.subtensor.AdvancedIncSubtensor1\n   0.0%    99.9%       0.007s       7.22e-06s     C     1000       1   theano.tensor.extra_ops.CumOp\n   0.0%   100.0%       0.004s       1.34e-06s     C     3000       3   theano.tensor.subtensor.AdvancedSubtensor1\n   0.0%   100.0%       0.003s       1.71e-06s     C     2000       2   theano.compile.ops.Shape_i\n   0.0%   100.0%       0.003s       1.60e-06s     C     2000       2   theano.tensor.opt.MakeVector\n   0.0%   100.0%       0.001s       1.30e-06s     C     1000       1   theano.tensor.basic.Reshape\n   0.0%   100.0%       0.001s       1.13e-06s     C     1000       1   theano.tensor.subtensor.Subtensor\n   0.0%   100.0%       0.001s       9.25e-07s     C     1000       1   theano.tensor.elemwise.All\n   0.0%   100.0%       0.000s       4.27e-07s     C     1000       1   theano.tensor.opt.Assert\n   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)\n\nOps\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>\n  42.3%    42.3%      10.467s       1.05e-02s     Py    1000        1   Cholesky{lower=True, destructive=False, nofail=False}\n  36.9%    79.1%       9.125s       9.12e-03s     C     1000        1   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)]\n  14.1%    93.3%       3.499s       3.50e-03s     Py    1000        1   Dot22Scalar\n   5.8%    99.1%       1.431s       7.16e-04s     Py    2000        2   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}\n   0.2%    99.2%       0.045s       4.50e-05s     Py    1000        1   Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}\n   0.1%    99.3%       0.023s       2.31e-05s     Py    1000        1   Dot22\n   0.1%    99.4%       0.022s       7.23e-06s     Py    3000        3   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}\n   0.1%    99.5%       0.019s       1.89e-05s     Py    1000        1   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}\n   0.1%    99.6%       0.014s       4.70e-06s     C     3000        3   Alloc\n   0.0%    99.6%       0.011s       1.11e-05s     C     1000        1   Elemwise{true_div,no_inplace}\n   0.0%    99.6%       0.008s       7.74e-06s     C     1000        1   IncSubtensor{InplaceInc;int64}\n   0.0%    99.7%       0.008s       7.60e-06s     C     1000        1   AdvancedIncSubtensor1{no_inplace,set}\n   0.0%    99.7%       0.007s       3.73e-06s     C     2000        2   Elemwise{Log}[(0, 0)]\n   0.0%    99.7%       0.007s       7.28e-06s     C     1000        1   Sum{axis=[1], acc_dtype=float64}\n   0.0%    99.8%       0.007s       7.22e-06s     C     1000        1   CumOp{None, add}\n   0.0%    99.8%       0.005s       2.64e-06s     C     2000        2   Elemwise{Sqr}[(0, 0)]\n   0.0%    99.8%       0.005s       4.81e-07s     C     10000       10   Sum{acc_dtype=float64}\n   0.0%    99.8%       0.004s       1.46e-06s     C     3000        3   InplaceDimShuffle{1,0}\n   0.0%    99.8%       0.004s       4.33e-06s     C     1000        1   IncSubtensor{InplaceInc;int64::}\n   0.0%    99.8%       0.004s       1.34e-06s     C     3000        3   AdvancedSubtensor1\n   ... (remaining 28 Ops account for   0.16%(0.04s) of the runtime)\n\nApply\n------\n<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>\n  42.3%    42.3%      10.467s       1.05e-02s   1000    46   Cholesky{lower=True, destructive=False, nofail=False}(Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)].0)\n  36.9%    79.1%       9.125s       9.12e-03s   1000    44   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)](TensorConstant{(1, 1) of -0.5}, Dot22Scalar.0, InplaceDimShuffle{0,x}.0, InplaceDimShuffle{x,0}.0, TensorConstant{(1, 1) of 0.0}, TensorConstant{(1, 1) of inf})\n  14.1%    93.3%       3.499s       3.50e-03s   1000    27   Dot22Scalar(Elemwise{true_div,no_inplace}.0, InplaceDimShuffle{1,0}.0, TensorConstant{-2.0})\n   5.5%    98.7%       1.354s       1.35e-03s   1000    49   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}(Cholesky{lower=True, destructive=False, nofail=False}.0, Elemwise{Sub}[(0, 1)].0)\n   0.3%    99.1%       0.077s       7.66e-05s   1000    57   Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0, Dot22.0)\n   0.2%    99.2%       0.045s       4.50e-05s   1000    61   Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}(InplaceDimShuffle{1,0}.0, Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}.0)\n   0.1%    99.3%       0.023s       2.31e-05s   1000    55   Dot22(InplaceDimShuffle{1,0}.0, Solve{A_structure='lower_triangular', lower=True, overwrite_A=False, overwrite_b=False}.0)\n   0.1%    99.4%       0.019s       1.89e-05s   1000    25   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}(Alloc.0, packed_L, TensorConstant{[0 1 1 2 2 2]}, TensorConstant{[0 0 1 0 1 2]})\n   0.0%    99.5%       0.011s       1.13e-05s   1000    12   Alloc(muvec, TensorConstant{1000}, TensorConstant{1}, TensorConstant{1}, Shape_i{0}.0)\n   0.0%    99.5%       0.011s       1.11e-05s   1000    15   Elemwise{true_div,no_inplace}(TensorConstant{[[ 0.25221..07868149]]}, InplaceDimShuffle{x,0}.0)\n   0.0%    99.5%       0.010s       9.65e-06s   1000    48   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Cholesky{lower=True, destructive=False, nofail=False}.0)\n   0.0%    99.6%       0.008s       8.11e-06s   1000    64   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(Solve{A_structure='upper_triangular', lower=False, overwrite_A=False, overwrite_b=False}.0)\n   0.0%    99.6%       0.008s       7.74e-06s   1000    37   IncSubtensor{InplaceInc;int64}(Alloc.0, Elemwise{sqr,no_inplace}.0, Constant{0})\n   0.0%    99.6%       0.008s       7.60e-06s   1000    20   AdvancedIncSubtensor1{no_inplace,set}(packed_L_cholesky_cov_packed__, Elemwise{Exp}[(0, 0)].0, TensorConstant{[0 2 5]})\n   0.0%    99.7%       0.007s       7.28e-06s   1000    35   Sum{axis=[1], acc_dtype=float64}(Elemwise{Sqr}[(0, 0)].0)\n   0.0%    99.7%       0.007s       7.22e-06s   1000    38   CumOp{None, add}(Elemwise{Sqr}[(0, 0)].0)\n   0.0%    99.7%       0.006s       6.09e-06s   1000    51   Elemwise{Log}[(0, 0)](ExtractDiag{offset=0, axis1=0, axis2=1, view=False}.0)\n   0.0%    99.7%       0.004s       4.43e-06s   1000    29   Elemwise{Sqr}[(0, 0)](Elemwise{true_div,no_inplace}.0)\n   0.0%    99.8%       0.004s       4.33e-06s   1000    47   IncSubtensor{InplaceInc;int64::}(IncSubtensor{InplaceInc;int64}.0, Elemwise{Sub}[(0, 0)].0, Constant{1})\n   0.0%    99.8%       0.004s       3.93e-06s   1000    30   ExtractDiag{offset=0, axis1=0, axis2=1, view=False}(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0)\n   ... (remaining 50 Apply instances account for 0.23%(0.06s) of the runtime)\n\nHere are tips to potentially make your code run faster\n                 (if you think of new ones, suggest them on the mailing list).\n                 Test them first, as they are not guaranteed to always provide a speedup.\n  - Try the Theano flag floatX=float32\n  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.\n"
     ]
    }
   ],
   "source": [
    "# Profile large models\n",
    "mn_large.profile(mn_large.logpt).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Function profiling\n==================\n  Message: /Users/neklein/Python/Environments/rdxgp/lib/python3.6/site-packages/pymc3/model.py:903\n  Time in 1000 calls to Function.__call__: 3.076107e+02s\n  Time in Function.fn.__call__: 3.075431e+02s (99.978%)\n  Time in thunks: 3.064911e+02s (99.636%)\n  Total compile time: 6.724150e-01s\n    Number of Apply nodes: 77\n    Theano Optimizer time: 4.298701e-01s\n       Theano validate time: 1.291370e-02s\n    Theano Linker time (includes C, CUDA code generation/compiling): 1.755798e-01s\n       Import time 0.000000e+00s\n       Node make_thunk time 1.720772e-01s\n           Node for{cpu,scan_fn}(TensorConstant{1}, Elemwise{Sub}[(0, 1)].0, TensorConstant{1}, ell, packed_L, Alloc.0) time 1.002209e-01s\n           Node Elemwise{Sub}[(0, 1)](TensorConstant{[[-0.29761..21279899]]}, InplaceDimShuffle{x,0}.0) time 2.564907e-02s\n           Node Elemwise{Mul}[(0, 1)](TensorConstant{0.5}, Sum{acc_dtype=float64}.0) time 2.330303e-03s\n           Node Elemwise{Sqr}[(0, 0)](InplaceDimShuffle{x}.0) time 1.440048e-03s\n           Node InplaceDimShuffle{x,0}(Elemwise{Add}[(0, 0)].0) time 1.353979e-03s\n\nTime in all call to theano.grad() 0.000000e+00s\nTime since theano import 2248.696s\nClass\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>\n  50.2%    50.2%     153.851s       1.54e-01s     Py    1000       1   theano.scan_module.scan_op.Scan\n  45.7%    95.9%     140.173s       7.01e-02s     Py    2000       2   theano.tensor.nlinalg.Eigh\n   2.9%    98.9%       8.975s       3.09e-04s     C    29000      29   theano.tensor.elemwise.Elemwise\n   1.1%    99.9%       3.337s       3.34e-03s     Py    1000       1   theano.tensor.blas.Dot22Scalar\n   0.0%   100.0%       0.024s       2.37e-05s     Py    1000       1   theano.tensor.blas.Dot22\n   0.0%   100.0%       0.021s       2.06e-05s     Py    1000       1   theano.tensor.subtensor.AdvancedIncSubtensor\n   0.0%   100.0%       0.017s       1.72e-06s     C    10000      10   theano.tensor.elemwise.DimShuffle\n   0.0%   100.0%       0.016s       7.89e-06s     C     2000       2   theano.tensor.subtensor.IncSubtensor\n   0.0%   100.0%       0.014s       1.56e-06s     C     9000       9   theano.tensor.elemwise.Sum\n   0.0%   100.0%       0.011s       2.82e-06s     C     4000       4   theano.tensor.basic.Alloc\n   0.0%   100.0%       0.011s       1.09e-05s     C     1000       1   theano.tensor.extra_ops.CumOp\n   0.0%   100.0%       0.010s       9.69e-06s     C     1000       1   theano.tensor.subtensor.AdvancedIncSubtensor1\n   0.0%   100.0%       0.009s       8.51e-06s     C     1000       1   theano.tensor.blas_c.CGer\n   0.0%   100.0%       0.007s       7.25e-06s     C     1000       1   theano.tensor.blas.BatchedDot\n   0.0%   100.0%       0.006s       1.99e-06s     C     3000       3   theano.tensor.subtensor.AdvancedSubtensor1\n   0.0%   100.0%       0.003s       1.43e-06s     C     2000       2   theano.tensor.opt.MakeVector\n   0.0%   100.0%       0.003s       1.34e-06s     C     2000       2   theano.tensor.subtensor.Subtensor\n   0.0%   100.0%       0.002s       1.21e-06s     C     2000       2   theano.tensor.basic.Reshape\n   0.0%   100.0%       0.001s       4.31e-07s     C     2000       2   theano.compile.ops.Shape_i\n   0.0%   100.0%       0.001s       7.97e-07s     C     1000       1   theano.tensor.elemwise.All\n   ... (remaining 1 Classes account for   0.00%(0.00s) of the runtime)\n\nOps\n---\n<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>\n  50.2%    50.2%     153.851s       1.54e-01s     Py    1000        1   for{cpu,scan_fn}\n  45.7%    95.9%     140.173s       7.01e-02s     Py    2000        2   Eigh{UPLO='L'}\n   2.9%    98.8%       8.900s       8.90e-03s     C     1000        1   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)]\n   1.1%    99.9%       3.337s       3.34e-03s     Py    1000        1   Dot22Scalar\n   0.0%    99.9%       0.024s       2.37e-05s     Py    1000        1   Dot22\n   0.0%    99.9%       0.021s       2.06e-05s     Py    1000        1   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}\n   0.0%    99.9%       0.015s       1.46e-05s     C     1000        1   Elemwise{Log}[(0, 0)]\n   0.0%    99.9%       0.011s       1.14e-05s     C     1000        1   Elemwise{true_div,no_inplace}\n   0.0%   100.0%       0.011s       2.82e-06s     C     4000        4   Alloc\n   0.0%   100.0%       0.011s       1.09e-05s     C     1000        1   CumOp{None, add}\n   0.0%   100.0%       0.010s       9.69e-06s     C     1000        1   AdvancedIncSubtensor1{no_inplace,set}\n   0.0%   100.0%       0.009s       8.67e-06s     C     1000        1   IncSubtensor{InplaceInc;int64}\n   0.0%   100.0%       0.009s       8.51e-06s     C     1000        1   CGer{destructive}\n   0.0%   100.0%       0.007s       7.25e-06s     C     1000        1   BatchedDot\n   0.0%   100.0%       0.007s       8.95e-07s     C     8000        8   Sum{acc_dtype=float64}\n   0.0%   100.0%       0.007s       7.10e-06s     C     1000        1   IncSubtensor{InplaceInc;int64::}\n   0.0%   100.0%       0.007s       6.86e-06s     C     1000        1   Sum{axis=[1], acc_dtype=float64}\n   0.0%   100.0%       0.007s       6.82e-06s     C     1000        1   Elemwise{sqrt,no_inplace}\n   0.0%   100.0%       0.006s       2.16e-06s     C     3000        3   Elemwise{Sqr}[(0, 0)]\n   0.0%   100.0%       0.006s       1.99e-06s     C     3000        3   AdvancedSubtensor1\n   ... (remaining 31 Ops account for   0.02%(0.06s) of the runtime)\n\nApply\n------\n<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>\n  50.2%    50.2%     153.851s       1.54e-01s   1000    44   for{cpu,scan_fn}(TensorConstant{1}, Elemwise{Sub}[(0, 1)].0, TensorConstant{1}, ell, packed_L, Alloc.0)\n  45.7%    95.9%     140.122s       1.40e-01s   1000    50   Eigh{UPLO='L'}(Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)].0)\n   2.9%    98.8%       8.900s       8.90e-03s   1000    47   Elemwise{Composite{exp((i0 * clip((i1 + i2 + i3), i4, i5)))}}[(0, 1)](TensorConstant{(1, 1) of -0.5}, Dot22Scalar.0, InplaceDimShuffle{0,x}.0, InplaceDimShuffle{x,0}.0, TensorConstant{(1, 1) of 0.0}, TensorConstant{(1, 1) of inf})\n   1.1%    99.9%       3.337s       3.34e-03s   1000    31   Dot22Scalar(Elemwise{true_div,no_inplace}.0, InplaceDimShuffle{1,0}.0, TensorConstant{-2.0})\n   0.0%    99.9%       0.051s       5.08e-05s   1000    41   Eigh{UPLO='L'}(Dot22.0)\n   0.0%    99.9%       0.024s       2.37e-05s   1000    37   Dot22(AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}.0, InplaceDimShuffle{1,0}.0)\n   0.0%    99.9%       0.021s       2.06e-05s   1000    27   AdvancedIncSubtensor{inplace=False,  set_instead_of_inc=True}(Alloc.0, packed_L, TensorConstant{[0 1 1 2 2 2]}, TensorConstant{[0 0 1 0 1 2]})\n   0.0%    99.9%       0.015s       1.46e-05s   1000    62   Elemwise{Log}[(0, 0)](Elemwise{Add}[(0, 0)].0)\n   0.0%    99.9%       0.011s       1.14e-05s   1000    20   Elemwise{true_div,no_inplace}(TensorConstant{[[ 0.25221..07868149]]}, InplaceDimShuffle{x,0}.0)\n   0.0%   100.0%       0.011s       1.09e-05s   1000    49   CumOp{None, add}(Elemwise{Sqr}[(0, 0)].0)\n   0.0%   100.0%       0.010s       9.69e-06s   1000    23   AdvancedIncSubtensor1{no_inplace,set}(packed_L_cholesky_cov_packed__, Elemwise{Exp}[(0, 0)].0, TensorConstant{[0 2 5]})\n   0.0%   100.0%       0.009s       8.67e-06s   1000    38   IncSubtensor{InplaceInc;int64}(Alloc.0, Elemwise{sqr,no_inplace}.0, Constant{0})\n   0.0%   100.0%       0.009s       8.51e-06s   1000    53   CGer{destructive}(Alloc.0, TensorConstant{1.0}, Eigh{UPLO='L'}.0, Eigh{UPLO='L'}.0)\n   0.0%   100.0%       0.007s       7.25e-06s   1000    69   BatchedDot(Elemwise{TrueDiv}[(0, 0)].0, Elemwise{TrueDiv}[(0, 0)].0)\n   0.0%   100.0%       0.007s       7.10e-06s   1000    56   IncSubtensor{InplaceInc;int64::}(IncSubtensor{InplaceInc;int64}.0, Elemwise{Sub}[(0, 0)].0, Constant{1})\n   0.0%   100.0%       0.007s       6.86e-06s   1000    39   Sum{axis=[1], acc_dtype=float64}(Elemwise{Sqr}[(0, 0)].0)\n   0.0%   100.0%       0.007s       6.82e-06s   1000    61   Elemwise{sqrt,no_inplace}(InplaceDimShuffle{x,0}.0)\n   0.0%   100.0%       0.006s       5.68e-06s   1000    64   Elemwise{TrueDiv}[(0, 0)](for{cpu,scan_fn}.0, Elemwise{sqrt,no_inplace}.0)\n   0.0%   100.0%       0.005s       4.67e-06s   1000     5   Alloc(TensorConstant{0.0}, TensorConstant{1000}, TensorConstant{3})\n   0.0%   100.0%       0.005s       4.56e-06s   1000    34   Elemwise{Sqr}[(0, 0)](Elemwise{true_div,no_inplace}.0)\n   ... (remaining 57 Apply instances account for 0.03%(0.08s) of the runtime)\n\n\nScan overhead:\n<Scan op time(s)> <sub scan fct time(s)> <sub scan op time(s)> <sub scan fct time(% scan op time)> <sub scan op time(% scan op time)> <node>\n  One scan node do not have its inner profile enabled. If you enable Theano profiler with 'theano.function(..., profile=True)', you must manually enable the profiling for each scan too: 'theano.scan_module.scan(...,profile=True)'. Or use Theano flag 'profile=True'.\n  No scan have its inner profile enabled.\nHere are tips to potentially make your code run faster\n                 (if you think of new ones, suggest them on the mailing list).\n                 Test them first, as they are not guaranteed to always provide a speedup.\n  - Try the Theano flag floatX=float32\n  - Try installing amdlibm and set the Theano flag lib.amdlibm=True. This speeds up only some Elemwise operation.\n"
     ]
    }
   ],
   "source": [
    "# Profile large models\n",
    "kn_large.profile(kn_large.logpt).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
